{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f8c6a76",
   "metadata": {},
   "source": [
    "# A) Random forest tuning & cross-validation \n",
    "\n",
    "Throughout the following exercises, we're going to use Python to **construct** and **validate** a random forest ensemble model with `scikit-learn`.\n",
    "\n",
    "**Note**: This notebook is divided into two parts. Begin here, or skip ahead to [Part 2](#part_2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd302d7",
   "metadata": {},
   "source": [
    "Topics of focus include:\n",
    "\n",
    "\n",
    "*   Relevant import statements\n",
    "*   Encoding of categorical features as dummies\n",
    "*   Stratification during data splitting\n",
    "*   Fitting a model\n",
    "*   Using `GridSearchCV` to cross-validate the model and tune the following hyperparameters:  \n",
    "    - `max_depth`  \n",
    "    - `max_features`  \n",
    "    - `min_samples_split`\n",
    "    - `n_estimators`  \n",
    "    - `min_samples_leaf`  \n",
    "*   Model evaluation using **precision, recall,** and **f1 score.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baa847f",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "This notebook is a continuation of the bank churn project. Below is a recap of the considerations and decisions that we've already made. For detailed discussion of these topics, refer back to the [fully annotated notebook for the decision tree model](https://www.coursera.org/learn/the-nuts-and-bolts-of-machine-learning/ungradedLab/HVyMU/annotated-follow-along-guide-build-a-decision-tree).\n",
    "\n",
    ">  **Modeling objective:** To predict whether a customer will churn&mdash;a binary classification task.\n",
    "\n",
    "\n",
    ">  **Target variable:** `Exited` column&mdash;0 or 1.  \n",
    "\n",
    ">  **Class balance:** The data is imbalanced 80/20 (not churned/churned), but we will not perform class balancing.\n",
    "\n",
    ">  **Primary evaluation metric:** F1 score.\n",
    "\n",
    ">  **Modeling workflow and model selection:** The champion model will be the model with the best validation F1 score. Only the champion model will be used to predict on the test data. See the annotated decision tree notebook for details and limitations of this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc57ee3c",
   "metadata": {},
   "source": [
    "## A note on cross-validation/validation\n",
    "\n",
    "For teaching purposes, we're going to include two approaches to validation in this notebook: **cross-validating the training data** and **validating using a separate validation dataset**. In practice, we generally will only use one or the other for a given project. \n",
    "\n",
    "**Cross-validation** is more rigorous, because it maximizes the usage of the training data, but if you have a very large dataset or limited computing resources, it may be better to **validate with a separate validation dataset**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f90fad",
   "metadata": {},
   "source": [
    "# 1) Import statements\n",
    "\n",
    "Before we begin with the exercises and analyzing the data, we need to import all libraries and extensions required for this programming exercise. Throughout the course, we will be using numpy and pandas for operations, and matplotlib for plotting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54de4e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# This lets us seel all the columns, preventing Jupyter from redacting them\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,\\\n",
    "confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#This module lets us save our models once we fit them\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef3a6f4",
   "metadata": {},
   "source": [
    "# 2) Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311d59a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data \n",
    "file = \"Churn_Modelling.csv\"\n",
    "df_original = pd.read_csv(file)\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7dcaf1",
   "metadata": {},
   "source": [
    "# 3) Feature engineering\n",
    "\n",
    "## 3.1) Feature selection\n",
    "\n",
    "In this step, we'll prepare the data for modeling.  Notice from above that there are a number of columns that we wouldn't expect to offer any predictive signal to the model. These columns include `RowNumber`, `CustomerID`, and `Surname`. We'll drop these columns so they don't introduce noise to our model.  \n",
    "\n",
    "We'll also drop the `Gender` column, because we don't want our model to make predictions based on gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30941fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619    France   42       2       0.00              1          1   \n",
       "1          608     Spain   41       1   83807.86              1          0   \n",
       "2          502    France   42       8  159660.80              3          1   \n",
       "3          699    France   39       1       0.00              2          0   \n",
       "4          850     Spain   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  \n",
       "0               1        101348.88       1  \n",
       "1               1        112542.58       0  \n",
       "2               0        113931.57       1  \n",
       "3               0         93826.63       0  \n",
       "4               1         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the useless and sensitive (Gender) cols\n",
    "churn_df = df_original.drop(columns= [\"RowNumber\", \"CustomerId\", \"Surname\", \"Gender\"], axis = 1)\n",
    "churn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b474e2",
   "metadata": {},
   "source": [
    "## 3.2) Feature transformation\n",
    "\n",
    "Next, we'll dummy encode the `Geography` variable, which is categorical. We do this with the `pd.get_dummies()` function and setting `drop_first='True'`, which replaces the `Geography` column with two new Boolean columns called `Geography_Germany` and `Geography_Spain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a4e9402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56934dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  Geography_Spain  \n",
       "0               1        101348.88       1                  0                0  \n",
       "1               1        112542.58       0                  0                1  \n",
       "2               0        113931.57       1                  0                0  \n",
       "3               0         93826.63       0                  0                0  \n",
       "4               1         79084.10       0                  0                1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy encode categoricals\n",
    "churn_df2 = pd.get_dummies(churn_df, drop_first= 'True')\n",
    "churn_df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2be5c8",
   "metadata": {},
   "source": [
    "# 4) Split the data\n",
    "\n",
    "We'll split the data into features and target variable, and into training data and test data using the `train_test_split()` function. \n",
    "\n",
    "Don't forget to include the `stratify=y` parameter, as this is what ensures that the 80/20 class ratio of the target variable is maintained in both the training and test datasets after splitting.\n",
    "\n",
    "Lastly, we set a random seed so we and others can reproduce our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ef800df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the y (target) variable\n",
    "y = churn_df2[\"Exited\"]\n",
    "\n",
    "# Define the X (predcitor) variables\n",
    "X = churn_df2.copy()\n",
    "X = X.drop(\"Exited\", axis= 1)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= .2, stratify= y ,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c9e9e1",
   "metadata": {},
   "source": [
    "# 5) Modeling\n",
    "\n",
    "## 5.1) Method 1 : Cross-validated hyperparameter tuning\n",
    "\n",
    "The cross-validation process is the same as it was for the decision tree model. The only difference is that we're tuning more hyperparameters now. The steps are included below as a review. \n",
    "\n",
    "For details on cross-validating with `GridSearchCV`, refer back to the decision tree notebook, or to the [GridSearchCV documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) in scikit-learn.\n",
    "\n",
    "<ins> **1. Instantiate the classifier `rf` (and set the `random_state`)**</in> \n",
    "\n",
    "<ins> **2. Create a dictionary of hyperparameters to search over**</in>\n",
    "\n",
    "<ins> **3. Create a dictionary of scoring metrics to capture**</in>\n",
    "\n",
    "<ins> **4. Instantiate the `GridSearchCV` object**</in>\n",
    " Pass as arguments:\n",
    "  - The classifier (`rf`)\n",
    "  - The dictionary of hyperparameters to search over (`cv_params`)\n",
    "  - The dictionary of scoring metrics (`scoring`)\n",
    "  - The number of cross-validation folds you want (`cv=5`)\n",
    "  - The scoring metric that you want GridSearch to use when it selects the \"best\" model (i.e., the model that performs best on average over all validation folds) (`refit='f1'`)\n",
    "\n",
    "<ins> **5. Fit the data (`X_train`, `y_train`) to the `GridSearchCV` object (`rf_cv`)**</in>\n",
    "\n",
    "Note that we use the `%%time` magic at the top of the cell. This outputs the final runtime of the cell. (Magic commands, often just called \"magics,\" are commands that are built into IPython to simplify common tasks. They begin with `%` or `%%`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efc925b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "cv_parameters = {\"max_depth\" : [2, 3, 4, 5, None],\n",
    "                \"min_samples_leaf\" : [1, 2, 3],\n",
    "                \"min_samples_split\" : [2, 3, 4],\n",
    "                \"max_features\" : [2, 3, 4],\n",
    "                \"n_estimators\" : [75, 100, 125, 150]\n",
    "                }\n",
    "\n",
    "scoring = {\"accuracy\", \"precision\", \"recall\", \"f1\"}\n",
    "\n",
    "rf_cv = GridSearchCV(estimator=rf, param_grid= cv_parameters, scoring= scoring, cv = 5, refit= \"f1\")\n",
    "\n",
    "#rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495f828a",
   "metadata": {},
   "source": [
    "<a name=\"part_2\"></a>\n",
    "\n",
    "# B) Random forest validation on separate dataset \n",
    "\n",
    "This section of the notebook will demonstrate how to construct and validate a random forest ensemble model in Python with `scikit-learn`. \n",
    "\n",
    "\n",
    "Topics of focus include:\n",
    "\n",
    "<ins>**1. Using `pickle` to save a fit model**</ins>\n",
    "\n",
    "<ins>**2. Using a separate dataset to tune hyperparameters and validate your model**</ins>\n",
    "\n",
    " - Splitting the training data to create a validation dataset\n",
    " - Creating a list of split indices to use with `PredefinedSplit` so `GridSearchCV` performs validation on this defined validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097808eb",
   "metadata": {},
   "source": [
    "# 1) Pickle \n",
    "\n",
    "When models take a long time to fit, you don’t want to have to fit them more than once. If your kernel disconnects or you shut down the notebook and lose the cell’s output, you’ll have to refit the model, which can be frustrating and time-consuming. \n",
    "\n",
    "`pickle` is a tool that saves the fit model object to a specified location, then quickly reads it back in. It also allows you to use models that were fit somewhere else, without having to train them yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1534e3d8",
   "metadata": {},
   "source": [
    "This step will ***W***rite (i.e., save) the model, in ***B***inary (hence, `wb`), to the folder designated by the above path. In this case, the name of the file we're writing is `rf_cv_model.pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94581287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b90990c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a path to the folder where you want to save the model\n",
    "path = \"/home/jovyan/work/\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a940a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the model\n",
    "with open(os.path.join(path, \"rf_cv_model.pickle\"), \"wb\") as to_write:\n",
    "    pickle.dump(rf_cv, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ca3494",
   "metadata": {},
   "source": [
    "Once we save the model, we'll never have to re-fit it when we run this notebook. Ideally, we could open the notebook, select \"Run all,\" and the cells would run successfully all the way to the end without any model retraining. \n",
    "\n",
    "For this to happen, we'll need to return to the cell where we defined our grid search and comment out the line where we fit the model. Otherwise, when we re-run the notebook, it would refit the model. \n",
    "\n",
    "Similarly, we'll also need to go back to where we saved the model as a pickle and comment out those lines.  \n",
    "\n",
    "Next, we'll add a new cell that reads in the saved model from the folder we already specified. For this, we'll use `rb` (read binary) and be sure to assign the model to the same variable name as we used above, `rf_cv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4de78045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in pickled model\n",
    "with open(path + \"rf_cv_model.pickle\", \"rb\") as to_read :\n",
    "    rf_cv =pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055a2eb7",
   "metadata": {},
   "source": [
    "Now everything above is ready to run quickly and without refitting. We can continue by using the model's `best_params_` attribute to check the hyperparameters that had the best average F1 score across all the cross-validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0060fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 4,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv.fit(X_train, y_train)\n",
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d359ad",
   "metadata": {},
   "source": [
    "And to check the best average F1 score of this model on the validation folds, we can use the `best_score_` attribute. Remember, if we had instead set `refit=recall` when we instantiated our `GridSearchCV` object earlier, then calling `best_score_` would return the best recall score, and the best parameters might not be the same as what they are in the above cell, because the model would be optimizing for a different metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ab2b89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5896155834106125"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d12b9a",
   "metadata": {},
   "source": [
    "Our model had an F1 score of 0.5896&mdash;not terrible. Recall that when we ran our grid search, we specified that we also wanted to capture precision, recall, and accuracy. \n",
    "\n",
    "The reason for doing this is that it's difficult to interpret an F1 score. These other metrics are much more directly interpretable, so they're worth knowing. \n",
    "\n",
    "The following cell defines a helper function that extracts these scores from the fit `GridSearchCV` object and returns a pandas dataframe with all four scores from the model with the best average F1 score during validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26ebaffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_results(model_name, model_object):\n",
    "    '''\n",
    "    Accepts as arguments a model name (your choice - string) and\n",
    "    a fit GridSearchCV model object.\n",
    "  \n",
    "    Returns a pandas df with the F1, recall, precision, and accuracy scores\n",
    "    for the model with the best mean F1 score across all validation folds.  \n",
    "    '''\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(mean f1 score)\n",
    "    best_estimator_results = cv_results.iloc[cv_results['mean_test_f1'].idxmax(), :]\n",
    "\n",
    "    # Extract accuracy, precision, recall, and f1 score from that row\n",
    "    f1 = best_estimator_results.mean_test_f1\n",
    "    recall = best_estimator_results.mean_test_recall\n",
    "    precision = best_estimator_results.mean_test_precision\n",
    "    accuracy = best_estimator_results.mean_test_accuracy\n",
    "  \n",
    "    # Create table of results\n",
    "    table = pd.DataFrame()\n",
    "    table = table.append({'Model': model_name,\n",
    "                        'F1': f1,\n",
    "                        'Recall': recall,\n",
    "                        'Precision': precision,\n",
    "                        'Accuracy': accuracy\n",
    "                        },\n",
    "                        ignore_index=True\n",
    "                       )\n",
    "  \n",
    "    return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8289b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Badr\\AppData\\Local\\Temp\\ipykernel_15616\\1295797167.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  table = table.append({'Model': model_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest CV</td>\n",
       "      <td>0.589616</td>\n",
       "      <td>0.480368</td>\n",
       "      <td>0.765121</td>\n",
       "      <td>0.863875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model        F1    Recall  Precision  Accuracy\n",
       "0  Random Forest CV  0.589616  0.480368   0.765121  0.863875"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a results table for the rf_cv model using above function\n",
    "rf_cv_results = make_results(\"Random Forest CV\", rf_cv)\n",
    "rf_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923a4537",
   "metadata": {},
   "source": [
    "We can concatenate these results to our master results table from when we built the single decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1e88369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in master results table\n",
    "results = pd.read_csv(\"results.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "082d7d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest CV</td>\n",
       "      <td>0.589616</td>\n",
       "      <td>0.480368</td>\n",
       "      <td>0.765121</td>\n",
       "      <td>0.863875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Decision Tree</td>\n",
       "      <td>0.560655</td>\n",
       "      <td>0.469255</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.850400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model        F1    Recall  Precision  Accuracy\n",
       "0     Random Forest CV  0.589616  0.480368   0.765121  0.863875\n",
       "0  Tuned Decision Tree  0.560655  0.469255   0.701608  0.850400"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the random forest results to the master table\n",
    "results = pd.concat([rf_cv_results, results])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1818c47d",
   "metadata": {},
   "source": [
    "The scores in the above table tell us that the random forest model performs better than the single decision tree model on every metric. Nice!\n",
    "\n",
    "Now, let's build another random forest model, only this time we'll tune the hyperparameters using a separate validation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74b5ba1",
   "metadata": {},
   "source": [
    "## 5.1) Method 2 : Hyperparameters tuned with separate validation set\n",
    "\n",
    "<ins>**1 - Begin by splitting the training data to create a validation dataset**</ins>\n",
    "\n",
    "Remember, we won't touch the test data at all, we'll use `train_test_split` to divide `X_train` and `y_train` into 80% training data (`X_tr`, `y_tr`) and 20% validation data (`X_val`, `y_val`). Don't forget to stratify it and set the random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c729f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size = 0.2,\n",
    "                                           stratify = y_train, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a26703",
   "metadata": {},
   "source": [
    "When we tune hyperparameters with `GridSearchCV` using a separate validation dataset, we have to take a few extra steps. `GridSearchCV` wants to cross-validate the data. In fact, if the `cv` argument were left blank, it would split the data into five folds for cross-validation by default. \n",
    "\n",
    "We don't want it to do this. Instead, we're going to tell it exactly which rows of `X_train` are for training, and which rows are for validation.  \n",
    "\n",
    "To do this, we need to make a list of length `len(X_train)` where each element is either a '0' or '-1'. A '0' in index _i_ will indicate to `GridSearchCV` that index _i_ of `X_train` is to be held out for validation. A '-1' at a given index will indicate that that index of `X_train` is to be used as training data. \n",
    "\n",
    "We'll make this list using a list comprehension that looks at the index number of each row in `X_train`. If that index number is in `X_val`'s list of index numbers, then the list comprehension appends a 0. If it's not, then it appends a -1.\n",
    "\n",
    "So if our training data is:  \n",
    "[A, B, C, D],  \n",
    "and our list is:   \n",
    "[-1, 0, 0, -1],  \n",
    "then `GridSearchCV` will use a training set of [A, D] and validation set of [B, C]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "17a2c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of split indices\n",
    "split_index = [0 if x in X_val.index else -1 for x in X_train.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55884bcc",
   "metadata": {},
   "source": [
    "Now that we have this list, we need to import a new function called `PredefinedSplit`. This function is what allows us to pass the list we just made to `GridSearchCV`. (You can read more about this function in the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.PredefinedSplit.html#sklearn.model_selection.PredefinedSplit).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89b95721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import PredefinedSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d7a5e1",
   "metadata": {},
   "source": [
    "<ins>**2 - Now we can build the model**</ins>\n",
    "\n",
    "Everything is the same as when we cross-validated, except this time we pass the `split_index` list to the `PredefinedSplit` function and assign it to a new variable called `custom_split`.\n",
    "\n",
    "Then we'll use this variable for the `cv` argument when we instantiate `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cb756e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 0)\n",
    "\n",
    "cv_parameters = {\n",
    "    'max_depth' : [2, 3, 4, 5, None],\n",
    "    'min_samples_leaf' : [1, 2, 3],\n",
    "    'min_samples_split' : [2, 3, 4],\n",
    "    'max_features' : [2, 3, 4],\n",
    "    'n_estimators' : [75, 100, 125, 150]\n",
    "}\n",
    "\n",
    "scoring = {\"accuracy\", \"precision\", \"recall\", \"f1\"}\n",
    "\n",
    "custom_split = PredefinedSplit(split_index)\n",
    "\n",
    "rf_val = GridSearchCV(estimator=rf, param_grid= cv_parameters, scoring= scoring, cv = custom_split, refit= \"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25888dca",
   "metadata": {},
   "source": [
    "<ins>**3 - Now we fit the model**</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6694b82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8min 44s\n",
      "Wall time: 9min 2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ..., -1, -1])),\n",
       "             estimator=RandomForestClassifier(random_state=0),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 3, 4, 5, None],\n",
       "                         &#x27;max_features&#x27;: [2, 3, 4],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 4],\n",
       "                         &#x27;n_estimators&#x27;: [75, 100, 125, 150]},\n",
       "             refit=&#x27;f1&#x27;, scoring={&#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;accuracy&#x27;, &#x27;f1&#x27;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ..., -1, -1])),\n",
       "             estimator=RandomForestClassifier(random_state=0),\n",
       "             param_grid={&#x27;max_depth&#x27;: [2, 3, 4, 5, None],\n",
       "                         &#x27;max_features&#x27;: [2, 3, 4],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 4],\n",
       "                         &#x27;n_estimators&#x27;: [75, 100, 125, 150]},\n",
       "             refit=&#x27;f1&#x27;, scoring={&#x27;precision&#x27;, &#x27;recall&#x27;, &#x27;accuracy&#x27;, &#x27;f1&#x27;})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ..., -1, -1])),\n",
       "             estimator=RandomForestClassifier(random_state=0),\n",
       "             param_grid={'max_depth': [2, 3, 4, 5, None],\n",
       "                         'max_features': [2, 3, 4],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'min_samples_split': [2, 3, 4],\n",
       "                         'n_estimators': [75, 100, 125, 150]},\n",
       "             refit='f1', scoring={'precision', 'recall', 'accuracy', 'f1'})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf_val.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df9c0a",
   "metadata": {},
   "source": [
    "Notice that this took less time than when we cross-validated&mdash;about 1/5 of the time. This is because _during cross-validation_ the training data was divided into five folds. An ensemble of trees was grown with a particular combination of hyperparameters on four folds of data, and validated on the fifth fold that was held out. This whole process happened for each of five holdout folds. Then, another ensemble was trained with the next combination of hyperparameters, repeating the whole process. This continued until there were no more combinations of hyperparameters to run. \n",
    "\n",
    "But now that we're _using a separate validation set,_ an ensemble is built for each combination of hyperparameters. Each ensemble is trained on the new training set and validated on the validation set. But this only happens _one time_ for each combination of hyperparameters, instead of _five times_ with cross-validation. That’s why the training time was only a fifth as long.\n",
    "\n",
    "Let's pickle the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a14eb1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle the model\n",
    "with open(path+'rf_val_model.pickle', 'wb') as to_write:\n",
    "    pickle.dump(rf_val, to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e817f8ab",
   "metadata": {},
   "source": [
    "... and comment out where we fit the model and wrote the pickle, then read back in the pickled model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e38b9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open pickled model\n",
    "with open(path + \"rf_val_model.pickle\", \"rb\") as to_read :\n",
    "    rf_val = pickle.load(to_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54430e3b",
   "metadata": {},
   "source": [
    "Now check the parameters of the best-performing model on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ffe580eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 4,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 75}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_val.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76592e7f",
   "metadata": {},
   "source": [
    "Notice that the best hyperparameters were slightly different than the cross-validated model.  \n",
    "\n",
    "Now, we'll generate the model results using the `make_results` function, add them to the master table, and then sort them by F1 score in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1bc53d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Badr\\AppData\\Local\\Temp\\ipykernel_15616\\1295797167.py:24: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  table = table.append({'Model': model_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Validated</td>\n",
       "      <td>0.609848</td>\n",
       "      <td>0.493865</td>\n",
       "      <td>0.797030</td>\n",
       "      <td>0.871250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest CV</td>\n",
       "      <td>0.589616</td>\n",
       "      <td>0.480368</td>\n",
       "      <td>0.765121</td>\n",
       "      <td>0.863875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned Decision Tree</td>\n",
       "      <td>0.560655</td>\n",
       "      <td>0.469255</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.850400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model        F1    Recall  Precision  Accuracy\n",
       "0  Random Forest Validated  0.609848  0.493865   0.797030  0.871250\n",
       "0         Random Forest CV  0.589616  0.480368   0.765121  0.863875\n",
       "0      Tuned Decision Tree  0.560655  0.469255   0.701608  0.850400"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model results table\n",
    "rf_val_results = make_results(\"Random Forest Validated\", rf_val)\n",
    "\n",
    "# Concatentate model results table with master results table\n",
    "results = pd.concat([rf_val_results, results])\n",
    "\n",
    "# Sort master results by F1 score in descending order\n",
    "results.sort_values(by = \"F1\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a8faf",
   "metadata": {},
   "source": [
    "We can save the new master table to use later when we build more models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ce67da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the master results table\n",
    "results.to_csv(path + \"results2.csv\", index = False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea655fb",
   "metadata": {},
   "source": [
    "# C) Model selection and final results\n",
    "\n",
    "Now we have three models. If we've decided that we're done trying to optimize them, then we can now use our best model to predict on the test holdout data. We'll be using the cross-validated model without the depth limitation, but if we were instead to use the model that was validated against a separate validation dataset, we'd now go back and retrain the model on the full training set (training + validation sets).\n",
    "\n",
    "**Note**: _It might be tempting to see how all models perform on the test holdout data, and then to choose the one that performs best. While this **can** be done, it biases the final model, because we used our test data to go back and make an upstream decision. The test data should represent **unseen** data. In competitions, for example, we must submit your final model before receiving the test data._\n",
    "\n",
    "The results in the table above tell us that the cross-validated random forest model performs a little better than the one trained on a separate validation set. \n",
    "\n",
    "It performs well for precision and accuracy, but the recall is 0.48. This means that out of all the people in the validation folds who _actually_ left the bank, the model successfully identifies 48% of them. \n",
    "\n",
    "We will not apply the model to the test data yet, because there is still one more model to build. We'll learn about this soon. Once we train that model, we'll use our champion model to predict on the test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
